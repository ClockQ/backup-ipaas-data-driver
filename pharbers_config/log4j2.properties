status = all
dest = all.log
name = PropertiesConfig
property.filename = log4j2.properties
filter.threshold.type = ThresholdFilter
filter.threshold.level = all

appender.console.type = Console
appender.console.name = STDOUT
appender.console.layout.type = PatternLayout
appender.console.layout.pattern = %m%n
appender.console.filter.threshold.type = ThresholdFilter
appender.console.filter.threshold.level = all

appender.rolling.type = RollingFile
appender.rolling.name = RollingFile
appender.rolling.fileName = logs/rolling.log
appender.rolling.filePattern = target/rolling2/test1-%d{MM-dd-yy-HH-mm-ss}-%i.log.gz
appender.rolling.layout.type = PatternLayout
appender.rolling.layout.pattern = %d %p %C{1.} [%t] %m%n
appender.rolling.policies.type = Policies
appender.rolling.policies.time.type = TimeBasedTriggeringPolicy
appender.rolling.policies.time.interval = 2
appender.rolling.policies.time.modulate = true
appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
appender.rolling.policies.size.size=1MB
appender.rolling.strategy.type = DefaultRolloverStrategy
appender.rolling.strategy.max = 5

appender.file.type = File
appender.file.name = File
appender.file.level = all
appender.file.fileName = logs/app.log
appender.file.layout.type = PatternLayout
appender.file.layout.pattern = %d %p %C{1.} [%t] %m%n
appender.file.Threshold.type=ThresholdFilter
appender.file.Threshold.level=all


#logger.file.level = all

logger.rolling.name = com.example.my.app
logger.rolling.level = all
logger.rolling.additivity = false
logger.rolling.appenderRef.rolling.ref = RollingFile

rootLogger.level = all
rootLogger.appenderRef.stdout.ref = STDOUT

## Settings to quiet third party logs that are too verbose
#log4j.logger.org.spark-project.jetty=WARN
#log4j.logger.org.spark-project.jetty.util.component.AbstractLifeCycle=ERROR
#log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
#log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
#log4j.logger.org.apache.parquet=ERROR
#log4j.logger.parquet=ERROR

## SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
#log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
#log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR
